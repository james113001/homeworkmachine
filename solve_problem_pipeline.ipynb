{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Model: Gemma by GOOGLE\n",
    "We are going to use gemma as our pretrained, open source LLM. This model will be loaded in using "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q --upgrade keras-nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (8.1.2)\n",
      "Requirement already satisfied: comm>=0.1.3 in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from ipywidgets) (8.24.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.10 in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from ipywidgets) (4.0.10)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.10 in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from ipywidgets) (3.0.10)\n",
      "Requirement already satisfied: decorator in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.42)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (2.18.0)\n",
      "Requirement already satisfied: stack-data in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (4.11.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q --upgrade keras  # Upgrade to Keras 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from tensorflow) (24.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from tensorflow) (1.64.0)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from tensorflow) (3.3.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from tensorflow) (0.37.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from tensorflow) (1.26.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: rich in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2023.11.17)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plotly in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (5.22.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from plotly) (8.3.0)\n",
      "Requirement already satisfied: packaging in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from plotly) (24.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (1.6.14)\n",
      "Requirement already satisfied: six>=1.10 in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from kaggle) (2023.11.17)\n",
      "Requirement already satisfied: python-dateutil in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from kaggle) (2.9.0)\n",
      "Requirement already satisfied: requests in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from kaggle) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from kaggle) (4.66.1)\n",
      "Requirement already satisfied: python-slugify in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: urllib3 in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from kaggle) (2.1.0)\n",
      "Requirement already satisfied: bleach in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from kaggle) (6.1.0)\n",
      "Requirement already satisfied: webencodings in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from bleach->kaggle) (0.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from requests->kaggle) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/kolbeweathington/miniconda3/envs/autogen/lib/python3.11/site-packages (from requests->kaggle) (3.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Math Director Prompt:\n",
    "\n",
    "You are the director of a mathematics solutions company;\n",
    "you will take a given math problem, \n",
    "and break the task down into a list of individual steps that must be completed to solve the task;\n",
    "\n",
    "for each math problem; you will delegate to a math solution assistant who will complete the task;\n",
    "\n",
    "ONLY say \"TERMINATE\" after you have returned a solution for the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Level</th>\n",
       "      <th>Type</th>\n",
       "      <th>Solution</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My school's math club has 6 boys and 8 girls. ...</td>\n",
       "      <td>Level 2</td>\n",
       "      <td>counting_and_probability</td>\n",
       "      <td>With no restrictions, we are merely picking 6 ...</td>\n",
       "      <td>3003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How many 4-letter words with at least one cons...</td>\n",
       "      <td>Level 3</td>\n",
       "      <td>counting_and_probability</td>\n",
       "      <td>First we count the number of all 4-letter word...</td>\n",
       "      <td>609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question    Level  \\\n",
       "0  My school's math club has 6 boys and 8 girls. ...  Level 2   \n",
       "1  How many 4-letter words with at least one cons...  Level 3   \n",
       "\n",
       "                       Type  \\\n",
       "0  counting_and_probability   \n",
       "1  counting_and_probability   \n",
       "\n",
       "                                            Solution Answer  \n",
       "0  With no restrictions, we are merely picking 6 ...   3003  \n",
       "1  First we count the number of all 4-letter word...    609  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\" # you can also use tensorflow or torch\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"0.9\" # avoid memory fragmentation on JAX backend.\n",
    "\n",
    "import keras\n",
    "import keras_nlp\n",
    "import kagglehub\n",
    "import kaggle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas() # progress bar for pandas\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "\n",
    "class CFG:\n",
    "    seed = 42\n",
    "    preset = \"gemma_1.1_instruct_2b_en\" # name of pretrained Gemma\n",
    "    sequence_length = 512 # max size of input sequence for training\n",
    "    batch_size = 1 # size of the input batch in training\n",
    "    epochs = 1 # number of epochs to train\n",
    "\n",
    "keras.utils.set_random_seed(CFG.seed)\n",
    "\n",
    "df1 = pd.read_csv(\"traincompiled.csv\")\n",
    "df2 = pd.read_csv(\"testcompiled.csv\")\n",
    "# df3 = pd.read_csv(\"AI Math Olympiad Prize/test.csv\")\n",
    "# df4 = pd.read_csv(\"AI Math Olympiad Prize/train.csv\")\n",
    "\n",
    "# df5 = pd.concat([df3, df4], axis=0)\n",
    "# df5.head(1)\n",
    "\n",
    "df = pd.concat([df1, df2], axis=0)\n",
    "df.head(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16449185999c431fa4940ef30b2b48d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7929 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "template = \"\"\"Role:\\nYou are an advanced AI system with exceptional mathematical reasoning and problem-solving capabilities, specifically designed to solve tricky math problems (whose answer is a non-negative integer) written in LaTeX format from the AI Mathematical Olympiad (AIMO) competition. Your task is to accurately analyze and solve intricate mathematical problems, demonstrating a deep understanding of mathematical concepts and a strong ability to apply logical reasoning strategies.\\n\\nInstruction:\n",
    "1. Carefully read and comprehend the problem statement provided in the \"Problem\" section.\n",
    "2. In the \"Solution\" section, provide a solution of the problem with detailed explanation of your logical reasoning process. Keep in mind that answer must be a non-negative integer number.\n",
    "3. At the end, create a \"Answer\" section where you will state only the final numerical or algebraic answer, without any additional text or narrative.\\n\\nProblem:\\n{problem}\\n\\nSolution:\\n{solution}\"\"\"\n",
    "\n",
    "df[\"prompt\"] = df.progress_apply(lambda row: template.format(problem=row.Question,\n",
    "                                                             solution=f\"{row.Solution}\\n\\nAnswer:\\n{row.Answer}\"),\n",
    "                                                             axis=1)\n",
    "data = df.prompt.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The code below is for the original problem set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# template = \"\"\"Role:\\nYou are an advanced AI system with exceptional mathematical reasoning and problem-solving capabilities, specifically designed to solve tricky math problems (whose answer is a non-negative integer) written in LaTeX format from the AI Mathematical Olympiad (AIMO) competition. Your task is to accurately analyze and solve intricate mathematical problems, demonstrating a deep understanding of mathematical concepts and a strong ability to apply logical reasoning strategies.\\n\\nInstruction:\n",
    "# 1. Carefully read and comprehend the problem statement provided in the \"Problem\" section.\n",
    "# 2. In the \"Solution\" section, provide a solution of the problem with detailed explanation of your logical reasoning process. Keep in mind that answer must be a non-negative integer number.\n",
    "# 3. At the end, create a \"Answer\" section where you will state only the final numerical or algebraic answer, without any additional text or narrative.\\n\\nProblem:\\n{problem}\\n\\nSolution:\\n{solution}\"\"\"\n",
    "\n",
    "# df[\"prompt\"] = df.progress_apply(lambda row: template.format(problem=row.Question,\n",
    "#                                                              solution=f\"{row.Solution}\\n\\nAnswer:\\n{row.Answer}\"),\n",
    "#                                                              axis=1)\n",
    "# data = df.prompt.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='blue'>Role:</font>**\n",
       "You are an advanced AI system with exceptional mathematical reasoning and problem-solving capabilities, specifically designed to solve tricky math problems (whose answer is a non-negative integer) written in LaTeX format from the AI Mathematical Olympiad (AIMO) competition. Your task is to accurately analyze and solve intricate mathematical problems, demonstrating a deep understanding of mathematical concepts and a strong ability to apply logical reasoning strategies.\n",
       "\n",
       "\n",
       "\n",
       "**<font color='yellow'>Instruction:</font>**\n",
       "1. Carefully read and comprehend the problem statement provided in the \"Problem\" section.\n",
       "2. In the \"Solution\" section, provide a solution of the problem with detailed explanation of your logical reasoning process. Keep in mind that answer must be a non-negative integer number.\n",
       "3. At the end, create a \"Answer\" section where you will state only the final numerical or algebraic answer, without any additional text or narrative.\n",
       "\n",
       "\n",
       "\n",
       "**<font color='red'>Problem:</font>**\n",
       "Each block on the grid shown in the Figure is 1 unit by 1 unit.  Suppose we wish to walk from $A$ to $B$ via a 7 unit path, but we have to stay on the grid -- no cutting across blocks.  How many different paths can we take?[asy]size(3cm,3cm);int w=5;int h=4;int i;for (i=0; i<h; ++i){draw((0,i) -- (w-1,i));}for (i=0; i<w; ++i){draw((i, 0)--(i,h-1));}label(\"B\", (w-1,h-1), NE);label(\"A\", (0,0), SW);[/asy]\n",
       "\n",
       "\n",
       "\n",
       "**<font color='cyan'>Solution:</font>**\n",
       "We know that we must take a 7 unit path.  If we look at the grid a little more carefully, we can see that our path must consist of 4 steps to the right and 3 steps up, and we can take those steps in any order.  So in order to specify a path, we must choose 3 of our 7 steps to be `up' (and the other 4 steps will thus be `right').  Hence the number of paths is $$ \\binom{7}{3} = \\frac{7 \\times 6 \\times 5}{3 \\times 2 \\times 1} = \\boxed{35}. $$\n",
       "\n",
       "\n",
       "\n",
       "**<font color='green'>Answer:</font>**\n",
       "35"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def colorize_text(text):\n",
    "    for word, color in zip([\"Role\", \"Instruction\", \"Problem\", \"Solution\", \"Answer\"],\n",
    "                           [\"blue\", \"yellow\", \"red\", \"cyan\", \"green\"]):\n",
    "        text = text.replace(f\"{word}:\", f\"\\n\\n**<font color='{color}'>{word}:</font>**\")\n",
    "    return text\n",
    "\n",
    "# Take a random sample\n",
    "sample = data[12]\n",
    "\n",
    "# Give colors to Instruction, Response and Category\n",
    "sample = colorize_text(sample)\n",
    "\n",
    "# Show sample in markdown\n",
    "display(Markdown(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/models/keras/gemma/keras/gemma_1.1_instruct_2b_en/3/download/task.json...\n",
      "Downloading from https://www.kaggle.com/api/v1/models/keras/gemma/keras/gemma_1.1_instruct_2b_en/3/download/preprocessor.json...\n",
      "normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Tokenizer (type)                                   </span>┃<span style=\"font-weight: bold\">                                             Vocab # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                   │                                             <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n",
       "└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mTokenizer (type)                                  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                            Vocab #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                   │                                             \u001b[38;5;34m256,000\u001b[0m │\n",
       "└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">524,288,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        │   \u001b[38;5;34m2,506,172,416\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
       "│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m524,288,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(CFG.preset)\n",
    "gemma_lm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_ids : (2, 8192)\n",
      "padding_mask : (2, 8192)\n"
     ]
    }
   ],
   "source": [
    "x, y, sample_weight = gemma_lm.preprocessor(data[0:2])\n",
    "\n",
    "# Display the shape of each processed output\n",
    "for k, v in x.items():\n",
    "    print(k, \":\", v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='blue'>Role:</font>**\n",
       "You are an advanced AI system with exceptional mathematical reasoning and problem-solving capabilities, specifically designed to solve tricky math problems (whose answer is a non-negative integer) written in LaTeX format from the AI Mathematical Olympiad (AIMO) competition. Your task is to accurately analyze and solve intricate mathematical problems, demonstrating a deep understanding of mathematical concepts and a strong ability to apply logical reasoning strategies.\n",
       "\n",
       "\n",
       "\n",
       "**<font color='yellow'>Instruction:</font>**\n",
       "1. Carefully read and comprehend the problem statement provided in the \"Problem\" section.\n",
       "2. In the \"Solution\" section, provide a solution of the problem with detailed explanation of your logical reasoning process. Keep in mind that answer must be a non-negative integer number.\n",
       "3. At the end, create a \"Answer\" section where you will state only the final numerical or algebraic answer, without any additional text or narrative.\n",
       "\n",
       "\n",
       "\n",
       "**<font color='red'>Problem:</font>**\n",
       "Each block on the grid shown in the Figure is 1 unit by 1 unit.  Suppose we wish to walk from $A$ to $B$ via a 7 unit path, but we have to stay on the grid -- no cutting across blocks.  How many different paths can we take?[asy]size(3cm,3cm);int w=5;int h=4;int i;for (i=0; i<h; ++i){draw((0,i) -- (w-1,i));}for (i=0; i<w; ++i){draw((i, 0)--(i,h-1));}label(\"B\", (w-1,h-1), NE);label(\"A\", (0,0), SW);[/asy]\n",
       "\n",
       "\n",
       "\n",
       "**<font color='cyan'>Solution:</font>**\n",
       "The grid contains 20 paths that can be taken from A to B.\n",
       "\n",
       "Explanation:\n",
       "We can solve this problem by applying the concept of combinations.  The formula for combinations is:\n",
       "\n",
       "$$C(n, r) = \\frac{n!}{r!(n-r)!}$$\n",
       "\n",
       "In this case, n = 5 and r = 7, so the number of different paths is:\n",
       "\n",
       "$$C(5, 7) = \\frac{5!}{7!(5-7)!} = 20$$\n",
       "\n",
       "\n",
       "\n",
       "**<font color='green'>Answer:</font>** 20"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Take one sample\n",
    "row = df.iloc[12]\n",
    "\n",
    "# Generate Prompt using template\n",
    "prompt = template.format(\n",
    "    problem=row.Question,\n",
    "    solution=\"\",\n",
    ")\n",
    "\n",
    "# Infer\n",
    "output = gemma_lm.generate(prompt, max_length=1024)\n",
    "\n",
    "# Colorize\n",
    "output = colorize_text(output)\n",
    "\n",
    "# Display in markdown\n",
    "display(Markdown(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='blue'>Role:</font>**\n",
       "You are an advanced AI system with exceptional mathematical reasoning and problem-solving capabilities, specifically designed to solve tricky math problems (whose answer is a non-negative integer) written in LaTeX format from the AI Mathematical Olympiad (AIMO) competition. Your task is to accurately analyze and solve intricate mathematical problems, demonstrating a deep understanding of mathematical concepts and a strong ability to apply logical reasoning strategies.\n",
       "\n",
       "\n",
       "\n",
       "**<font color='yellow'>Instruction:</font>**\n",
       "1. Carefully read and comprehend the problem statement provided in the \"Problem\" section.\n",
       "2. In the \"Solution\" section, provide a solution of the problem with detailed explanation of your logical reasoning process. Keep in mind that answer must be a non-negative integer number.\n",
       "3. At the end, create a \"Answer\" section where you will state only the final numerical or algebraic answer, without any additional text or narrative.\n",
       "\n",
       "\n",
       "\n",
       "**<font color='red'>Problem:</font>**\n",
       "Let $A$ equal the number of four digit odd numbers.  Let $B$ equal the number of four digit multiples of 5.  Find $A+B$.\n",
       "\n",
       "\n",
       "\n",
       "**<font color='cyan'>Solution:</font>**\n",
       "**Step 1: Identify the key information**\n",
       "\n",
       "- The problem asks to find the sum of two quantities: $A$ and $B$.\n",
       "- $A$ represents the number of four digit odd numbers.\n",
       "- $B$ represents the number of four digit multiples of 5.\n",
       "\n",
       "**Step 2: Formulate a mathematical equation**\n",
       "\n",
       "$$A + B = ?$$\n",
       "\n",
       "**Step 3: Solve for the answer**\n",
       "\n",
       "Since the problem asks for an integer answer, we need to find a solution where $A+B$ is a non-negative integer.  The only way this can happen is if:\n",
       "\n",
       "$$A = 1, B = 4$$\n",
       "\n",
       "Therefore, the solution to the problem is:\n",
       "\n",
       "$$A+B = 1+4 = 5$$"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Take one sample\n",
    "row = df.iloc[32]\n",
    "\n",
    "# Generate Prompt using template\n",
    "prompt = template.format(\n",
    "    problem=row.Question,\n",
    "    solution=\"\"\n",
    ")\n",
    "\n",
    "# Infer\n",
    "output = gemma_lm.generate(prompt, max_length=1024)\n",
    "\n",
    "# Colorize\n",
    "output = colorize_text(output)\n",
    "\n",
    "# Display in markdown\n",
    "display(Markdown(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As of right now it seems like the llm is having trouble identifying what exactly the model is asking it to do, and subsequently what exact format the answer should be in. I'm thinking there should be a model to essentially read over the problem, identify the core goal, and format it to in a way that a manager can give the ok on proceeding with attempting to solve it.\n",
    "\n",
    "So now it's Solution manager: Problem extrapolator, Mathmatician, Solution checker"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
