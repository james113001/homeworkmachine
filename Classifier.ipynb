{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e70aa64-d69a-4cc2-88aa-3dd69150faa1",
   "metadata": {},
   "source": [
    "# Text Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddeaab47-46bb-40a2-bc80-7d22e3b52630",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.41.0-py3-none-any.whl.metadata (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting evaluate\n",
      "  Downloading evaluate-0.4.2-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-0.30.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting filelock (from transformers)\n",
      "  Downloading filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.23.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.23.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in /opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
      "  Downloading tokenizers-0.19.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages (from transformers) (4.66.4)\n",
      "Collecting datasets>=2.0.0 (from evaluate)\n",
      "  Downloading datasets-2.19.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting dill (from evaluate)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages (from evaluate) (2.2.2)\n",
      "Collecting xxhash (from evaluate)\n",
      "  Downloading xxhash-3.4.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from evaluate)\n",
      "  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec>=2021.05.0 (from fsspec[http]>=2021.05.0->evaluate)\n",
      "  Downloading fsspec-2024.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: psutil in /opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages (from accelerate) (5.9.8)\n",
      "Collecting torch>=1.10.0 (from accelerate)\n",
      "  Downloading torch-2.3.0-cp312-none-macosx_11_0_arm64.whl.metadata (26 kB)\n",
      "Collecting pyarrow>=12.0.0 (from datasets>=2.0.0->evaluate)\n",
      "  Using cached pyarrow-16.1.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (3.0 kB)\n",
      "Collecting pyarrow-hotfix (from datasets>=2.0.0->evaluate)\n",
      "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting fsspec>=2021.05.0 (from fsspec[http]>=2021.05.0->evaluate)\n",
      "  Downloading fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting aiohttp (from datasets>=2.0.0->evaluate)\n",
      "  Using cached aiohttp-3.9.5-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/opt/certifi/lib/python3.12/site-packages (from requests->transformers) (2024.2.2)\n",
      "Collecting sympy (from torch>=1.10.0->accelerate)\n",
      "  Downloading sympy-1.12-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch>=1.10.0->accelerate)\n",
      "  Downloading networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages (from pandas->evaluate) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages (from pandas->evaluate) (2024.1)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets>=2.0.0->evaluate)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets>=2.0.0->evaluate)\n",
      "  Using cached frozenlist-1.4.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets>=2.0.0->evaluate)\n",
      "  Using cached multidict-6.0.5-cp312-cp312-macosx_11_0_arm64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets>=2.0.0->evaluate)\n",
      "  Using cached yarl-1.9.4-cp312-cp312-macosx_11_0_arm64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
      "Collecting mpmath>=0.19 (from sympy->torch>=1.10.0->accelerate)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Downloading transformers-4.41.0-py3-none-any.whl (9.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-0.30.1-py3-none-any.whl (302 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.6/302.6 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading datasets-2.19.1-py3-none-any.whl (542 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.0/172.0 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.23.1-py3-none-any.whl (401 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.3/401.3 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.3-cp312-cp312-macosx_11_0_arm64.whl (411 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.1/411.1 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.19.1-cp312-cp312-macosx_11_0_arm64.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading torch-2.3.0-cp312-none-macosx_11_0_arm64.whl (61.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.14.0-py3-none-any.whl (12 kB)\n",
      "Downloading multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.7/146.7 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.4.1-cp312-cp312-macosx_11_0_arm64.whl (30 kB)\n",
      "Using cached aiohttp-3.9.5-cp312-cp312-macosx_11_0_arm64.whl (392 kB)\n",
      "Using cached pyarrow-16.1.0-cp312-cp312-macosx_11_0_arm64.whl (26.0 MB)\n",
      "Downloading networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hUsing cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached frozenlist-1.4.1-cp312-cp312-macosx_11_0_arm64.whl (51 kB)\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached multidict-6.0.5-cp312-cp312-macosx_11_0_arm64.whl (29 kB)\n",
      "Using cached yarl-1.9.4-cp312-cp312-macosx_11_0_arm64.whl (79 kB)\n",
      "Installing collected packages: mpmath, xxhash, sympy, safetensors, pyarrow-hotfix, pyarrow, networkx, multidict, fsspec, frozenlist, filelock, dill, yarl, torch, multiprocess, huggingface-hub, aiosignal, tokenizers, aiohttp, accelerate, transformers, datasets, evaluate\n",
      "Successfully installed accelerate-0.30.1 aiohttp-3.9.5 aiosignal-1.3.1 datasets-2.19.1 dill-0.3.8 evaluate-0.4.2 filelock-3.14.0 frozenlist-1.4.1 fsspec-2024.3.1 huggingface-hub-0.23.1 mpmath-1.3.0 multidict-6.0.5 multiprocess-0.70.16 networkx-3.3 pyarrow-16.1.0 pyarrow-hotfix-0.6 safetensors-0.4.3 sympy-1.12 tokenizers-0.19.1 torch-2.3.0 transformers-4.41.0 xxhash-3.4.1 yarl-1.9.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers evaluate accelerate datasets scikit-learn torch tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0f48b85-3334-4167-89c1-0def0b843ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pylatexenc\n",
      "  Downloading pylatexenc-2.10.tar.gz (162 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: pylatexenc\n",
      "  Building wheel for pylatexenc (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pylatexenc: filename=pylatexenc-2.10-py3-none-any.whl size=136816 sha256=02b4f6b42155aa02ba350fd5d24470db0ca086e2f5fb840166083234aee29155\n",
      "  Stored in directory: /Users/jameskim/Library/Caches/pip/wheels/06/3e/78/fa1588c1ae991bbfd814af2bcac6cef7a178beee1939180d46\n",
      "Successfully built pylatexenc\n",
      "Installing collected packages: pylatexenc\n",
      "Successfully installed pylatexenc-2.10\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pylatexenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b6576b28-2ab9-40ae-ab62-3114c4266311",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load your dataset\n",
    "train_df = pd.read_csv('ALLtraincompiled.csv')\n",
    "test_df = pd.read_csv('ALLtestcompiled.csv')\n",
    "\n",
    "train_df = train_df[['Question','Type']]\n",
    "test_df = test_df[['Question','Type']]\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "# train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the label mapping\n",
    "label_mapping = {'counting_and_probability': 0, 'intermediate_algebra': 1, 'number_theory': 2, 'precalculus':3, \n",
    "                'prealgebra':4, 'geometry':5, 'algebra':6}\n",
    "train_df['Type'] = train_df['Type'].map(label_mapping)\n",
    "test_df['Type'] = test_df['Type'].map(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e07afe5-6bc9-473c-a5a1-930d02e637d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Type\n",
       "6    1744\n",
       "1    1295\n",
       "4    1205\n",
       "5     870\n",
       "2     869\n",
       "0     771\n",
       "3     746\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25060ec4-91e5-434c-beea-ea774e60c22e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Type\n",
       "6    1187\n",
       "1     903\n",
       "4     871\n",
       "3     546\n",
       "2     540\n",
       "5     479\n",
       "0     474\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c3799834-755e-458a-a18f-7888b6530d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cedric has deposited $\\$12,\\!000$ into an account that pays $5\\%$ interest compounded annually.\n",
      "\n",
      "Daniel has deposited $\\$12,\\!000$ into an account that pays $7\\%$ simple annual interest.\n",
      "\n",
      "In $15$ years Cedric and Daniel compare their respective balances. To the nearest dollar, what is the positive difference between their balances?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def remove_commas_from_latex_numbers(text):\n",
    "    # Regular expression to match numbers with commas\n",
    "    pattern = r'(\\$[1-9]\\d{0,2}(,\\!?\\d{3})*(\\.\\d+)?\\$)'\n",
    "\n",
    "    # Function to remove commas from matched numbers\n",
    "    def remove_commas(match):\n",
    "        return match.group().replace(',', '').replace(r'\\!', '')\n",
    "\n",
    "    # Replace commas in matched numbers\n",
    "    result = re.sub(pattern, remove_commas, text)\n",
    "    return result\n",
    "\n",
    "# Example input string\n",
    "input_text = r\"\"\"\n",
    "Cedric has deposited $\\$12,\\!000$ into an account that pays $5\\%$ interest compounded annually.\n",
    "\n",
    "Daniel has deposited $\\$12,\\!000$ into an account that pays $7\\%$ simple annual interest.\n",
    "\n",
    "In $15$ years Cedric and Daniel compare their respective balances. To the nearest dollar, what is the positive difference between their balances?\n",
    "\"\"\"\n",
    "\n",
    "# Apply the function to the input string\n",
    "output_text = remove_commas_from_latex_numbers(input_text)\n",
    "\n",
    "# Print the output string\n",
    "print(output_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7883bd0d-5752-4f50-b019-856aa99ae03e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Question  \\\n",
      "0     A board game spinner is divided into three par...   \n",
      "1     My school's math club has 6 boys and 8 girls. ...   \n",
      "2     How many 4-letter words with at least one cons...   \n",
      "3     Melinda will roll two standard six-sided dice ...   \n",
      "4     Let $p$ be the probability that, in the proces...   \n",
      "...                                                 ...   \n",
      "7495  If $\\displaystyle\\frac{q}{r} = 9$, $\\displayst...   \n",
      "7496              Factor the expression $x(x+2)+(x+2)$.   \n",
      "7497  Cedric has deposited $\\$12,\\!000$ into an acco...   \n",
      "7498  Rural School USA has 105 students enrolled. Th...   \n",
      "7499  Jo adds up all the positive integers from 1 to...   \n",
      "\n",
      "                                          Latex_Phrases  \\\n",
      "0         [A, B, C, A, \\frac{1}{3}, B, \\frac{5}{12}, C]   \n",
      "1                                                    []   \n",
      "2                              [A, B, C, D, E, B, C, D]   \n",
      "3                                                    []   \n",
      "4                          [p, 5, 2, p, m/n, m, n, m+n]   \n",
      "...                                                 ...   \n",
      "7495  [\\displaystyle\\frac{q}{r} = 9, \\displaystyle\\f...   \n",
      "7496                                     [x(x+2)+(x+2)]   \n",
      "7497  [\\,  into an account that pays , \\,  into an a...   \n",
      "7498                        [\\frac{1}{10}, \\frac{1}{3}]   \n",
      "7499                                                 []   \n",
      "\n",
      "                                              Math_Text  \\\n",
      "0                         [A, B, C, A, 1/3, B, 5/12, C]   \n",
      "1                                                    []   \n",
      "2                              [A, B, C, D, E, B, C, D]   \n",
      "3                                                    []   \n",
      "4                          [p, 5, 2, p, m/n, m, n, m+n]   \n",
      "...                                                 ...   \n",
      "7495                 [q/r = 9, s/r = 6, s/t = 1/2, t/q]   \n",
      "7496                                     [x(x+2)+(x+2)]   \n",
      "7497  [,  into an account that pays , ,  into an acc...   \n",
      "7498                                        [1/10, 1/3]   \n",
      "7499                                                 []   \n",
      "\n",
      "                                           New_Question  \n",
      "0     A board game spinner is divided into three par...  \n",
      "1     My school's math club has 6 boys and 8 girls. ...  \n",
      "2     How many 4-letter words with at least one cons...  \n",
      "3     Melinda will roll two standard six-sided dice ...  \n",
      "4     Let p be the probability that, in the process ...  \n",
      "...                                                 ...  \n",
      "7495  If q/r = 9, s/r = 6, and s/t = 1/2, then what ...  \n",
      "7496                Factor the expression x(x+2)+(x+2).  \n",
      "7497  Cedric has deposited 12,\\!000 into an account ...  \n",
      "7498  Rural School USA has 105 students enrolled. Th...  \n",
      "7499  Jo adds up all the positive integers from 1 to...  \n",
      "\n",
      "[7500 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from pylatexenc.latex2text import LatexNodes2Text\n",
    "\n",
    "\n",
    "def remove_comma_from_latex(latex_list):\n",
    "    # Regular expression to match numbers with commas\n",
    "    pattern = r'\\$([1-9][0-9]{3,}|[1-9][0-9]{5,})'  \n",
    "    \n",
    "    # Function to remove commas from matched numbers\n",
    "    def remove_comma(match):\n",
    "        return match.group().replace(',', '')\n",
    "    \n",
    "    # Replace commas in numbers >= 1000 for each element in the list\n",
    "    modified_latex_list = []\n",
    "    for latex in latex_list:\n",
    "        modified_latex = re.sub(pattern, remove_comma, latex)\n",
    "        modified_latex_list.append(modified_latex)\n",
    "        \n",
    "    return modified_latex_list\n",
    "# Test the function with an example\n",
    "# latex_value = r\"$12,\\!000$\"\n",
    "\n",
    "\n",
    "# Function to extract LaTeX phrases\n",
    "def extract_latex(text):\n",
    "    return re.findall(r'\\$(.*?)\\$', text)\n",
    "\n",
    "# Function to convert LaTeX to plain text\n",
    "def convert_latex_to_text(latex_phrases):\n",
    "    converter = LatexNodes2Text()\n",
    "    return [converter.latex_to_text(phrase) for phrase in latex_phrases]\n",
    "\n",
    "def replace_latex_with_text(question, latex_phrases, text_phrases):\n",
    "    for latex, text in zip(latex_phrases, text_phrases):\n",
    "        question = question.replace(f\"${latex}$\", text)\n",
    "    return question\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Extract LaTeX phrases and convert them\n",
    "# train_df['Question'] = train_df['Question'].apply(remove_comma_from_latex)\n",
    "train_df['Latex_Phrases'] = train_df['Question'].apply(extract_latex)\n",
    "train_df['Math_Text'] = train_df['Latex_Phrases'].apply(convert_latex_to_text)\n",
    "train_df['New_Question'] = train_df.apply(lambda row: replace_latex_with_text(row['Question'], row['Latex_Phrases'], row['Math_Text']), axis=1)\n",
    "\n",
    "\n",
    "# # Print the DataFrame\n",
    "print(train_df[['Question','Latex_Phrases','Math_Text','New_Question']])\n",
    "train_df.to_csv('questions_with_plain_text.csv', index=False)\n",
    "\n",
    "# train_df['Question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f158e696-7375-4c6d-9e04-cc144760c70f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The number of increasing sequences of positive integers a_1 ≤a_2 ≤a_3 ≤⋯≤a_10 ≤2007 such that a_i-i is even for 1≤i ≤10 can be expressed as m n for some positive integers m > n. Compute the remainder when m is divided by 1000.\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['New_Question'].iloc[8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7446ba3-a8ec-4f93-a30d-8d4645a5466e",
   "metadata": {},
   "source": [
    "https://github.com/purdue-tlt/latex2sympy/tree/master\n",
    "\n",
    "Use this in terminal to download\n",
    "\n",
    "pip install wheel\n",
    "pip install \"cython<3.0.0\" && pip install --no-build-isolation pyyaml==6.0 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "593813c2-b100-48dd-a93d-8a32629b31ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting latex2sympy2\n",
      "  Downloading latex2sympy2-1.9.1-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: sympy>=1.4 in /opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages (from latex2sympy2) (1.12)\n",
      "Collecting antlr4-python3-runtime==4.7.2 (from latex2sympy2)\n",
      "  Downloading antlr4-python3-runtime-4.7.2.tar.gz (112 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.3/112.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages (from sympy>=1.4->latex2sympy2) (1.3.0)\n",
      "Downloading latex2sympy2-1.9.1-py3-none-any.whl (89 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.8/89.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: antlr4-python3-runtime\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.7.2-py3-none-any.whl size=140931 sha256=929bede0eda7eb678ffa16b4431046a1067e1fe97d7dae34f879106297706035\n",
      "  Stored in directory: /Users/jameskim/Library/Caches/pip/wheels/24/09/d5/906109a0b239813cee4d939fa6ccee45f63a19e3f774405e34\n",
      "Successfully built antlr4-python3-runtime\n",
      "Installing collected packages: antlr4-python3-runtime, latex2sympy2\n",
      "Successfully installed antlr4-python3-runtime-4.7.2 latex2sympy2-1.9.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install latex2sympy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cd6c1a56-e613-4693-8dca-bead02480b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\$'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\$'\n",
      "/var/folders/bs/zggx74yj4d721rnp57yp6h5r0000gn/T/ipykernel_52452/721610512.py:1: SyntaxWarning: invalid escape sequence '\\$'\n",
      "  latexx= '$\\$12,\\!000$'\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "I don't understand this\n \\ 12,\\!000 \n~^",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLexerNoViableAltException\u001b[0m                 Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages/antlr4/Lexer.py:128\u001b[0m, in \u001b[0;36mLexer.nextToken\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 128\u001b[0m     ttype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m LexerNoViableAltException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages/antlr4/atn/LexerATNSimulator.py:99\u001b[0m, in \u001b[0;36mLexerATNSimulator.match\u001b[0;34m(self, input, mode)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 99\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecATN\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdfa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ms0\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages/antlr4/atn/LexerATNSimulator.py:191\u001b[0m, in \u001b[0;36mLexerATNSimulator.execATN\u001b[0;34m(self, input, ds0)\u001b[0m\n\u001b[1;32m    189\u001b[0m     s \u001b[38;5;241m=\u001b[39m target \u001b[38;5;66;03m# flip; current DFA target becomes new src/from state\u001b[39;00m\n\u001b[0;32m--> 191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfailOrAccept\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprevAccept\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfigs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages/antlr4/atn/LexerATNSimulator.py:250\u001b[0m, in \u001b[0;36mLexerATNSimulator.failOrAccept\u001b[0;34m(self, prevAccept, input, reach, t)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Token\u001b[38;5;241m.\u001b[39mEOF\n\u001b[0;32m--> 250\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m LexerNoViableAltException(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecog, \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstartIndex, reach)\n",
      "\u001b[0;31mLexerNoViableAltException\u001b[0m: LexerNoViableAltException('\\')",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m latexx\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m$\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m$12,\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m!000$\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mlatex2sympy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlatexx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages/latex2sympy2.py:97\u001b[0m, in \u001b[0;36mlatex2sympy\u001b[0;34m(sympy, variable_values)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# process the input\u001b[39;00m\n\u001b[1;32m     96\u001b[0m return_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 97\u001b[0m math \u001b[38;5;241m=\u001b[39m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmath\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# if a list\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m math\u001b[38;5;241m.\u001b[39mrelation_list():\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages/gen/PSParser.py:1017\u001b[0m, in \u001b[0;36mPSParser.math\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmath\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1016\u001b[0m     localctx \u001b[38;5;241m=\u001b[39m PSParser\u001b[38;5;241m.\u001b[39mMathContext(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ctx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate)\n\u001b[0;32m-> 1017\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menterRule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocalctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRULE_math\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1018\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1019\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m130\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages/antlr4/Parser.py:366\u001b[0m, in \u001b[0;36mParser.enterRule\u001b[0;34m(self, localctx, state, ruleIndex)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m state\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ctx \u001b[38;5;241m=\u001b[39m localctx\n\u001b[0;32m--> 366\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ctx\u001b[38;5;241m.\u001b[39mstart \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLT\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuildParseTrees:\n\u001b[1;32m    368\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maddContextToParseTree()\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages/antlr4/CommonTokenStream.py:61\u001b[0m, in \u001b[0;36mCommonTokenStream.LT\u001b[0;34m(self, k)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mLT\u001b[39m(\u001b[38;5;28mself\u001b[39m, k:\u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m---> 61\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlazyInit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     63\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages/antlr4/BufferedTokenStream.py:186\u001b[0m, in \u001b[0;36mBufferedTokenStream.lazyInit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlazyInit\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 186\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages/antlr4/BufferedTokenStream.py:189\u001b[0m, in \u001b[0;36mBufferedTokenStream.setup\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msetup\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 189\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madjustSeekIndex(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages/antlr4/BufferedTokenStream.py:111\u001b[0m, in \u001b[0;36mBufferedTokenStream.sync\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    109\u001b[0m n \u001b[38;5;241m=\u001b[39m i \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokens) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;66;03m# how many more elements we need?\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m :\n\u001b[0;32m--> 111\u001b[0m     fetched \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fetched \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m n\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages/antlr4/BufferedTokenStream.py:123\u001b[0m, in \u001b[0;36mBufferedTokenStream.fetch\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, n):\n\u001b[0;32m--> 123\u001b[0m     t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenSource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnextToken\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m     t\u001b[38;5;241m.\u001b[39mtokenIndex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokens)\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokens\u001b[38;5;241m.\u001b[39mappend(t)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages/antlr4/Lexer.py:130\u001b[0m, in \u001b[0;36mLexer.nextToken\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    128\u001b[0m     ttype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interp\u001b[38;5;241m.\u001b[39mmatch(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode)\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m LexerNoViableAltException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 130\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnotifyListeners\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\t\t\u001b[38;5;66;03m# report error\u001b[39;00m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecover(e)\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input\u001b[38;5;241m.\u001b[39mLA(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m==\u001b[39mToken\u001b[38;5;241m.\u001b[39mEOF:\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages/antlr4/Lexer.py:285\u001b[0m, in \u001b[0;36mLexer.notifyListeners\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    283\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken recognition error at: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgetErrorDisplay(text) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    284\u001b[0m listener \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgetErrorListenerDispatch()\n\u001b[0;32m--> 285\u001b[0m \u001b[43mlistener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msyntaxError\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tokenStartLine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tokenStartColumn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages/antlr4/error/ErrorListener.py:60\u001b[0m, in \u001b[0;36mProxyErrorListener.syntaxError\u001b[0;34m(self, recognizer, offendingSymbol, line, column, msg, e)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msyntaxError\u001b[39m(\u001b[38;5;28mself\u001b[39m, recognizer, offendingSymbol, line, column, msg, e):\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delegate \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelegates:\n\u001b[0;32m---> 60\u001b[0m         \u001b[43mdelegate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msyntaxError\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecognizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffendingSymbol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages/latex2sympy2.py:141\u001b[0m, in \u001b[0;36mMathErrorListener.syntaxError\u001b[0;34m(self, recog, symbol, line, col, msg, e)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    140\u001b[0m     err \u001b[38;5;241m=\u001b[39m fmt \u001b[38;5;241m%\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt understand this\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msrc, marker)\n\u001b[0;32m--> 141\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(err)\n",
      "\u001b[0;31mException\u001b[0m: I don't understand this\n \\ 12,\\!000 \n~^"
     ]
    }
   ],
   "source": [
    "latexx= '$\\$12,\\!000$'\n",
    "latex2sympy(latexx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aad11f7e-a782-418b-a35e-5f1867f599b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binomial(m, n)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\c'\n",
      "/var/folders/bs/zggx74yj4d721rnp57yp6h5r0000gn/T/ipykernel_52452/3262760491.py:3: SyntaxWarning: invalid escape sequence '\\c'\n",
      "  x = latex2sympy(\"${m \\choose n}$\")\n"
     ]
    }
   ],
   "source": [
    "from latex2sympy2 import latex2sympy\n",
    "\n",
    "train_df['sympy_column'] = train_df['latex_column'].apply(convert_to_sympy)\n",
    "print(x)\n",
    "# => \"diff(x**(2), x)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f92d1631-db77-4c9e-8fa3-7356554fc316",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79654d53e5834786bc3c578eb0766713",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object, got 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 45\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mpad({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m: tokenized_problem}, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Tokenization function\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Tokenization function with debugging\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# def tokenize_function(examples):\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     43\u001b[0m \n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Apply tokenization\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenize_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m test_dataset\u001b[38;5;241m.\u001b[39mmap(tokenize_function, batched\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Set format for PyTorch tensors\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages/datasets/arrow_dataset.py:602\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    600\u001b[0m     \u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    601\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 602\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    603\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m datasets:\n\u001b[1;32m    605\u001b[0m     \u001b[38;5;66;03m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages/datasets/arrow_dataset.py:567\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    560\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[1;32m    562\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[1;32m    563\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[1;32m    565\u001b[0m }\n\u001b[1;32m    566\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 567\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    568\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    569\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages/datasets/arrow_dataset.py:3156\u001b[0m, in \u001b[0;36mDataset.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   3150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transformed_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3151\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m hf_tqdm(\n\u001b[1;32m   3152\u001b[0m         unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m examples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3153\u001b[0m         total\u001b[38;5;241m=\u001b[39mpbar_total,\n\u001b[1;32m   3154\u001b[0m         desc\u001b[38;5;241m=\u001b[39mdesc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMap\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3155\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m-> 3156\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_single\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdataset_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   3157\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   3158\u001b[0m \u001b[43m                \u001b[49m\u001b[43mshards_done\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages/datasets/arrow_dataset.py:3547\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[0;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[1;32m   3543\u001b[0m indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m   3544\u001b[0m     \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m*\u001b[39m(\u001b[38;5;28mslice\u001b[39m(i, i \u001b[38;5;241m+\u001b[39m batch_size)\u001b[38;5;241m.\u001b[39mindices(shard\u001b[38;5;241m.\u001b[39mnum_rows)))\n\u001b[1;32m   3545\u001b[0m )  \u001b[38;5;66;03m# Something simpler?\u001b[39;00m\n\u001b[1;32m   3546\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3547\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[43mapply_function_on_filtered_inputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3548\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3549\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3550\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_same_num_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mshard\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_indexes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3551\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3552\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3553\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m NumExamplesMismatchError:\n\u001b[1;32m   3554\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DatasetTransformationNotAllowedError(\n\u001b[1;32m   3555\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing `.map` in batched mode on a dataset with attached indexes is allowed only if it doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt create or remove existing examples. You can first run `.drop_index() to remove your index and then re-add it.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3556\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages/datasets/arrow_dataset.py:3416\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001b[0;34m(pa_inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[1;32m   3414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m with_rank:\n\u001b[1;32m   3415\u001b[0m     additional_args \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (rank,)\n\u001b[0;32m-> 3416\u001b[0m processed_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43madditional_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed_inputs, LazyDict):\n\u001b[1;32m   3418\u001b[0m     processed_inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   3419\u001b[0m         k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mkeys_to_format\n\u001b[1;32m   3420\u001b[0m     }\n",
      "Cell \u001b[0;32mIn[33], line 19\u001b[0m, in \u001b[0;36mtokenize_function\u001b[0;34m(examples)\u001b[0m\n\u001b[1;32m     17\u001b[0m problem_text \u001b[38;5;241m=\u001b[39m examples[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQuestion\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Find LaTeX expressions and tokenize them separately\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m matches \u001b[38;5;241m=\u001b[39m \u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinditer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlatex_pattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproblem_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m tokenized_problem \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     21\u001b[0m last_end \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12/re/__init__.py:224\u001b[0m, in \u001b[0;36mfinditer\u001b[0;34m(pattern, string, flags)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfinditer\u001b[39m(pattern, string, flags\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    220\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return an iterator over all non-overlapping matches in the\u001b[39;00m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;124;03m    string.  For each match, the iterator returns a Match object.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \n\u001b[1;32m    223\u001b[0m \u001b[38;5;124;03m    Empty matches are included in the result.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinditer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstring\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object, got 'list'"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# Convert DataFrames to Hugging Face Dataset\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "# Load BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', add_special_tokens=True)\n",
    "\n",
    "\n",
    "latex_pattern = r'\\$([^$]*)\\$'\n",
    "\n",
    "# Tokenization function with LaTeX support\n",
    "def tokenize_function(examples):\n",
    "    # Tokenize each problem while preserving LaTeX\n",
    "    problem_text = examples['Question']\n",
    "    # Find LaTeX expressions and tokenize them separately\n",
    "    matches = re.finditer(latex_pattern, problem_text)\n",
    "    tokenized_problem = []\n",
    "    last_end = 0\n",
    "    for match in matches:\n",
    "        start, end = match.span()\n",
    "        # Tokenize text before LaTeX expression\n",
    "        tokenized_problem.extend(tokenizer.tokenize(problem_text[last_end:start]))\n",
    "        # Tokenize LaTeX expression and add each token separately\n",
    "        latex_expression = match.group(1)\n",
    "        tokenized_latex = tokenizer.tokenize(latex_expression)\n",
    "        tokenized_problem.extend(tokenized_latex)\n",
    "        last_end = end\n",
    "    # Tokenize the remaining text after the last LaTeX expression\n",
    "    tokenized_problem.extend(tokenizer.tokenize(problem_text[last_end:]))\n",
    "    return tokenizer.pad({'input_ids': tokenized_problem}, return_tensors='pt')\n",
    "\n",
    "# Tokenization function\n",
    "# Tokenization function with debugging\n",
    "# def tokenize_function(examples):\n",
    "#     tokenized_inputs = tokenizer(examples['Question'], padding='max_length', truncation=True)\n",
    "#     # print(\"Example:\", examples['Question'])\n",
    "#     # print(\"Tokenized inputs:\", tokenized_inputs)\n",
    "#     return tokenized_inputs\n",
    "\n",
    "\n",
    "# Apply tokenization\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "\n",
    "# Set format for PyTorch tensors\n",
    "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'Type'])\n",
    "test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'Type'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d403aaa-f860-462d-a985-c3c04ba00e1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting peft\n",
      "  Downloading peft-0.11.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages (from peft) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages (from peft) (24.0)\n",
      "Requirement already satisfied: psutil in /opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages (from peft) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in /opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages (from peft) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in /opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages (from peft) (2.3.0)\n",
      "Requirement already satisfied: transformers in /opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages (from peft) (4.41.0)\n",
      "Requirement already satisfied: tqdm in /opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages (from peft) (4.66.4)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages (from peft) (0.30.1)\n",
      "Requirement already satisfied: safetensors in /opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages (from peft) (0.4.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in /opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages (from peft) (0.23.1)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages (from huggingface-hub>=0.17.0->peft) (3.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages (from huggingface-hub>=0.17.0->peft) (2024.3.1)\n",
      "Requirement already satisfied: requests in /opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages (from huggingface-hub>=0.17.0->peft) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages (from huggingface-hub>=0.17.0->peft) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages (from torch>=1.13.0->peft) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages (from torch>=1.13.0->peft) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages (from torch>=1.13.0->peft) (3.1.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages (from transformers->peft) (2024.5.15)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages (from transformers->peft) (0.19.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/opt/certifi/lib/python3.12/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
      "Downloading peft-0.11.1-py3-none-any.whl (251 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.6/251.6 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: peft\n",
      "Successfully installed peft-0.11.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d96ef27-b856-403f-89c8-0048347cecf8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Invalid key: 7278 is out of bounds for size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 39\u001b[0m\n\u001b[1;32m     30\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     31\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     32\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer,\n\u001b[1;32m     36\u001b[0m )\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages/transformers/trainer.py:1885\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1883\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1884\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1885\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages/transformers/trainer.py:2178\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2175\u001b[0m     rng_to_sync \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   2177\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 2178\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   2179\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtotal_batched_samples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m   2181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minclude_num_input_tokens_seen\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages/accelerate/data_loader.py:454\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;66;03m# We iterate one batch ahead to check when we are at the end\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 454\u001b[0m     current_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages/datasets/arrow_dataset.py:2865\u001b[0m, in \u001b[0;36mDataset.__getitems__\u001b[0;34m(self, keys)\u001b[0m\n\u001b[1;32m   2863\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitems__\u001b[39m(\u001b[38;5;28mself\u001b[39m, keys: List) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List:\n\u001b[1;32m   2864\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Can be used to get a batch using a list of integers indices.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2865\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2866\u001b[0m     n_examples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch[\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(batch))])\n\u001b[1;32m   2867\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [{col: array[i] \u001b[38;5;28;01mfor\u001b[39;00m col, array \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems()} \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_examples)]\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages/datasets/arrow_dataset.py:2861\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2859\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):  \u001b[38;5;66;03m# noqa: F811\u001b[39;00m\n\u001b[1;32m   2860\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2861\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages/datasets/arrow_dataset.py:2845\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[0;34m(self, key, **kwargs)\u001b[0m\n\u001b[1;32m   2843\u001b[0m format_kwargs \u001b[38;5;241m=\u001b[39m format_kwargs \u001b[38;5;28;01mif\u001b[39;00m format_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m   2844\u001b[0m formatter \u001b[38;5;241m=\u001b[39m get_formatter(format_type, features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mfeatures, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mformat_kwargs)\n\u001b[0;32m-> 2845\u001b[0m pa_subtable \u001b[38;5;241m=\u001b[39m \u001b[43mquery_table\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_indices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2846\u001b[0m formatted_output \u001b[38;5;241m=\u001b[39m format_table(\n\u001b[1;32m   2847\u001b[0m     pa_subtable, key, formatter\u001b[38;5;241m=\u001b[39mformatter, format_columns\u001b[38;5;241m=\u001b[39mformat_columns, output_all_columns\u001b[38;5;241m=\u001b[39moutput_all_columns\n\u001b[1;32m   2848\u001b[0m )\n\u001b[1;32m   2849\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m formatted_output\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages/datasets/formatting/formatting.py:587\u001b[0m, in \u001b[0;36mquery_table\u001b[0;34m(table, key, indices)\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    586\u001b[0m     size \u001b[38;5;241m=\u001b[39m indices\u001b[38;5;241m.\u001b[39mnum_rows \u001b[38;5;28;01mif\u001b[39;00m indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m table\u001b[38;5;241m.\u001b[39mnum_rows\n\u001b[0;32m--> 587\u001b[0m     \u001b[43m_check_valid_index_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;66;03m# Query the main table\u001b[39;00m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages/datasets/formatting/formatting.py:537\u001b[0m, in \u001b[0;36m_check_valid_index_key\u001b[0;34m(key, size)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Iterable):\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(key) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 537\u001b[0m         \u001b[43m_check_valid_index_key\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    538\u001b[0m         _check_valid_index_key(\u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mmin\u001b[39m(key)), size\u001b[38;5;241m=\u001b[39msize)\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.2.0/libexec/lib/python3.12/site-packages/datasets/formatting/formatting.py:527\u001b[0m, in \u001b[0;36m_check_valid_index_key\u001b[0;34m(key, size)\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (key \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;241m+\u001b[39m size \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (key \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m size):\n\u001b[0;32m--> 527\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid key: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is out of bounds for size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    528\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mslice\u001b[39m):\n",
      "\u001b[0;31mIndexError\u001b[0m: Invalid key: 7278 is out of bounds for size 0"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertForSequenceClassification, TrainingArguments, Trainer\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "# Load BERT model for sequence classification\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)\n",
    "\n",
    "# Apply LoRA to the BERT model\n",
    "config = LoraConfig(\n",
    "    r=8,  # Rank of the low-rank matrices\n",
    "    lora_alpha=32,  # Scaling factor for the LoRA updates\n",
    "    target_modules=[\"query\", \"key\", \"value\"],  # Apply LoRA to these layers\n",
    "    lora_dropout=0.1,  # Dropout rate\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, config)\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "# Define Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
